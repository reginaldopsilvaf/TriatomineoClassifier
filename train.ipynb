{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DlvigMvnNLb_"
   },
   "outputs": [],
   "source": [
    "# https://medium.com/ai-techsystems/insect-classification-2c89e7398ec4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.linkedin.com/pulse/using-ai-recognize-kissing-bugs-mobile-phone-images-lorenzo-pattori/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://web.stanford.edu/~nanbhas/blog/sigmoid-softmax/#:~:text=And%20the%20sigmoid%20can%20now,belongs%20to%20the%20negative%20class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DxjwN_Ldbw1r",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Import libraries and set configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 6829,
     "status": "ok",
     "timestamp": 1712452898203,
     "user": {
      "displayName": "REGINALDO PEREIRA DA SILVA FILHO",
      "userId": "04353618630986426896"
     },
     "user_tz": 180
    },
    "id": "F4LYXQCUA0K0"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as ks\n",
    "import tensorflow.keras.models as model_loader\n",
    "import tensorflow.keras.utils as image_loader\n",
    "import tensorflow.nn as activation_function\n",
    "from PIL import Image\n",
    "from rembg import remove\n",
    "import os\n",
    "from keras.activations import relu\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import layers as Layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, \n",
    "                        inter_op_parallelism_threads=2, \n",
    "                        allow_soft_placement=True,\n",
    "                        device_count = {'CPU': 1})\n",
    "\n",
    "session = tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3x-Q0_Szb46e",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Get and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where images are present\n",
    "valid_dir = '../valid_ds'\n",
    "train_dir = '../train_ds'\n",
    "num_fldrs = 2\n",
    "target_size = (224,224)\n",
    "insect_names = {'1':\"triatomineo\",'2':\"outro_inseto\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datapreprocessing(train_dir, valid_dir, batch_size):\n",
    "    from tensorflow.keras.utils import image_dataset_from_directory\n",
    "\n",
    "    train_ds = image_dataset_from_directory(\n",
    "        directory=train_dir,\n",
    "        image_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        )\n",
    "\n",
    "    valid_ds = image_dataset_from_directory(\n",
    "        directory=valid_dir,\n",
    "        image_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        )\n",
    "    \n",
    "    return train_ds, valid_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_ds, valid_ds = datapreprocessing(train_dir, valid_dir, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_random_Flip = tf.keras.layers.RandomFlip(\"horizontal_and_vertical\")\n",
    "data_random_rotation = tf.keras.layers.RandomRotation(0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentation(ds):\n",
    "    aug1 = ds.map(lambda x, y: (data_random_Flip(x), y))\n",
    "    aug2 = ds.map(lambda x, y: (data_random_rotation(x), y))\n",
    "    \n",
    "    ds = ds.concatenate(aug1)\n",
    "    ds = ds.concatenate(aug2)\n",
    " \n",
    "    return ds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_train_ds = augmentation(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The training dataset was updated from {len(list(train_ds))} to {len(list(aug_train_ds))} image batchs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8-OIglUCH17-",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## CNN model (ResNet18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 252,
     "status": "ok",
     "timestamp": 1712452993714,
     "user": {
      "displayName": "REGINALDO PEREIRA DA SILVA FILHO",
      "userId": "04353618630986426896"
     },
     "user_tz": 180
    },
    "id": "qWcUy1MNEnOV"
   },
   "outputs": [],
   "source": [
    "class ResBlock(Model):\n",
    "    def __init__(self, channels, stride=1):\n",
    "        super(ResBlock, self).__init__(name='ResBlock')\n",
    "        self.flag = (stride != 1)\n",
    "        self.conv1 = Conv2D(channels, 3, stride, padding='same')\n",
    "        self.bn1 = BatchNormalization()\n",
    "        self.conv2 = Conv2D(channels, 3, padding='same')\n",
    "        self.bn2 = BatchNormalization()\n",
    "        self.relu = ReLU()\n",
    "        if self.flag:\n",
    "            self.bn3 = BatchNormalization()\n",
    "            self.conv3 = Conv2D(channels, 1, stride)\n",
    "\n",
    "    def call(self, x):\n",
    "        x1 = self.conv1(x)\n",
    "        x1 = self.bn1(x1)\n",
    "        x1 = self.relu(x1)\n",
    "        x1 = self.conv2(x1)\n",
    "        x1 = self.bn2(x1)\n",
    "        if self.flag:\n",
    "            x = self.conv3(x)\n",
    "            x = self.bn3(x)\n",
    "        x1 = Layers.add([x, x1])\n",
    "        x1 = self.relu(x1)\n",
    "        return x1\n",
    "\n",
    "\n",
    "class ResNet18(Model):\n",
    "    def __init__(self):\n",
    "        super(ResNet18, self).__init__(name='ResNet18')\n",
    "        self.conv1 = Conv2D(64, 7, 2, padding='same')\n",
    "        self.bn = BatchNormalization()\n",
    "        self.relu = ReLU()\n",
    "        self.mp1 = MaxPooling2D(pool_size=(2, 2), strides=2, padding=\"same\")\n",
    "\n",
    "        self.conv2_1 = ResBlock(64)\n",
    "        self.conv2_2 = ResBlock(64)\n",
    "\n",
    "        self.conv3_1 = ResBlock(128, 2)\n",
    "        self.conv3_2 = ResBlock(128)\n",
    "\n",
    "        self.conv4_1 = ResBlock(256, 2)\n",
    "        self.conv4_2 = ResBlock(256)\n",
    "\n",
    "        self.conv5_1 = ResBlock(512, 2)\n",
    "        self.conv5_2 = ResBlock(512)\n",
    "\n",
    "        self.pool = GlobalAveragePooling2D()\n",
    "        self.flat = Flatten()\n",
    "        self.fc = Dense(2, name=\"output\")\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.mp1(x)\n",
    "\n",
    "        x = self.conv2_1(x)\n",
    "        x = self.conv2_2(x)\n",
    "\n",
    "        x = self.conv3_1(x)\n",
    "        x = self.conv3_2(x)\n",
    "\n",
    "        x = self.conv4_1(x)\n",
    "        x = self.conv4_2(x)\n",
    "\n",
    "        x = self.conv5_1(x)\n",
    "        x = self.conv5_2(x)\n",
    "\n",
    "        x = self.pool(x)\n",
    "        x = self.flat(x)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "model = ResNet18()\n",
    "model.build(input_shape=(1, 224, 224, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vPzVKtInMV6_",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 250,
     "status": "ok",
     "timestamp": 1712453049495,
     "user": {
      "displayName": "REGINALDO PEREIRA DA SILVA FILHO",
      "userId": "04353618630986426896"
     },
     "user_tz": 180
    },
    "id": "8h5n5XgTEvdV"
   },
   "outputs": [],
   "source": [
    "def compiler(model,train_ds,valid_ds,epchs,lr):\n",
    "    early_stopping = ks.callbacks.EarlyStopping(monitor='val_accuracy',patience=10,\n",
    "                                         verbose=1,restore_best_weights=True)\n",
    "    #red_lr= ks.callbacks.ReduceLROnPlateau(monitor='val_accuracy',patience=20,verbose=1,factor=0.1)\n",
    "    opt = ks.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "    model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                      optimizer=opt,\n",
    "                      metrics=[\"accuracy\"])\n",
    "    history = model.fit(train_ds,\n",
    "                        epochs=epchs,\n",
    "                        callbacks=[early_stopping],\n",
    "                        validation_data=valid_ds\n",
    "                        )\n",
    "    #Visualise curves\n",
    "    plt.plot(history.history['accuracy'], label='train_acc')\n",
    "    plt.plot(history.history['val_accuracy'], label='valid_acc')\n",
    "\n",
    "    plt.title('lrate='+str(lr), pad=-50)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    return model,history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aWb2F_f3E-uF"
   },
   "outputs": [],
   "source": [
    "model = compiler(model,aug_train_ds,valid_ds,100,lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "va-fBkmfI3Yh",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "CwohvENyYNWX"
   },
   "outputs": [],
   "source": [
    "model[0].save(filepath='../cnn_model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(filepath='../cnn_model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Triatomineo inferences (validation images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = '../valid_ds/triatomineo'\n",
    "target_size = (224, 224)\n",
    "results = []\n",
    "\n",
    "# Definir opções de impressão do NumPy para formatar números decimais completos\n",
    "np.set_printoptions(precision=2, suppress=True)\n",
    "for img in os.listdir(dir):\n",
    "  image = image_loader.load_img(dir+'/'+img, target_size=target_size)\n",
    "  image_arr = np.array([image])\n",
    "\n",
    "  output = np.array(activation_function.softmax(model.predict(image_arr)))[0] * 100\n",
    "  results.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erros = 0\n",
    "for count, img in enumerate(os.listdir(dir)):\n",
    "    #print(img, f'É um barbeiro com uma certeza de aprox. {results[count][1]}%' if results[count][1] > results[count][0] else \n",
    "    #  f'Não é um barbeiro com uma certeza de aprox. {results[count][0]}%')\n",
    "    print(f'Inferência incorreta de {img} com {results[count]}' if results[count][1] <= results[count][0] else None)\n",
    "    if results[count][1] <= results[count][0]:\n",
    "        erros += 1\n",
    "soma = len(os.listdir(dir))\n",
    "print(f'\\nPorcentagem de acerto é de {((soma - erros) / soma) * 100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Non-triatomineo inferences (validation images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = '../outro_inseto'\n",
    "target_size = (224, 224)\n",
    "results = []\n",
    "\n",
    "# Definir opções de impressão do NumPy para formatar números decimais completos\n",
    "np.set_printoptions(precision=2, suppress=True)\n",
    "for img in os.listdir(dir):\n",
    "  image = image_loader.load_img(dir+'/'+img, target_size=target_size)\n",
    "  image_arr = np.array([image])\n",
    "\n",
    "  output = np.array(activation_function.softmax(model.predict(image_arr)))[0] * 100\n",
    "  results.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erros = 0\n",
    "for count, img in enumerate(os.listdir(dir)):\n",
    "    #print(img, f'É um barbeiro com uma certeza de aprox. {results[count][1]}%' if results[count][1] > results[count][0] else \n",
    "    #  f'Não é um barbeiro com uma certeza de aprox. {results[count][0]}%')\n",
    "    print(f'Inferência incorreta de {img} com {results[count]}' if results[count][0] <= results[count][1] else None)\n",
    "    if results[count][0] <= results[count][1]:\n",
    "        erros += 1\n",
    "soma = len(os.listdir(dir))\n",
    "print(f'Porcentagem de acerto é de {((soma - erros) / soma) * 100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Confusion's Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def criar_matriz_confusao(verdadeiro_positivo_A, verdadeiro_negativo_B, total_A, total_B):\n",
    "    falso_positivo_B = total_B - verdadeiro_negativo_B\n",
    "    falso_negativo_A = total_A - verdadeiro_positivo_A\n",
    "    \n",
    "#    matriz_confusao = np.array([[verdadeiro_positivo_A / total_A, falso_negativo_A / total_A], \n",
    "#                                [falso_positivo_B / total_B, verdadeiro_negativo_B / total_B]])\n",
    "\n",
    "    matriz_confusao = np.array([[verdadeiro_positivo_A, falso_negativo_A], \n",
    "                                [falso_positivo_B, verdadeiro_negativo_B]])\n",
    "\n",
    "#    matriz_confusao_porcentagem = matriz_confusao * 100\n",
    "#    matriz_confusao_porcentagem = np.round(matriz_confusao_porcentagem, 2)\n",
    "\n",
    "    return matriz_confusao\n",
    "\n",
    "# Dados fornecidos\n",
    "verdadeiro_positivo_A = 61\n",
    "verdadeiro_negativo_B = 59\n",
    "total_A = 66\n",
    "total_B = 66\n",
    "\n",
    "# Chamada da função para criar a matriz de confusão\n",
    "matriz = criar_matriz_confusao(verdadeiro_positivo_A, verdadeiro_negativo_B, total_A, total_B)\n",
    "\n",
    "# Criar o gráfico da matriz de confusão\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(matriz, cmap='viridis')\n",
    "\n",
    "# Adicionar textos dentro dos quadrados\n",
    "for i in range(len(matriz)):\n",
    "    for j in range(len(matriz[i])):\n",
    "        text = ax.text(j, i, matriz[i, j],\n",
    "                       ha=\"center\", va=\"center\", color=\"black\", fontsize=18, bbox={'facecolor': 'white', 'alpha': 1.0, 'pad': 5})\n",
    "\n",
    "# Adicionar rótulos aos eixos\n",
    "ax.set_xticks(np.arange(len(matriz)))\n",
    "ax.set_yticks(np.arange(len(matriz)))\n",
    "ax.set_xticklabels(['Triatomineo', 'Outro inseto'])\n",
    "ax.set_yticklabels(['Triatomineo', 'Outro inseto'])\n",
    "ax.set_xlabel('Predição')\n",
    "ax.set_ylabel('Verdadeiro valor')\n",
    "\n",
    "# Adicionar barra de cores\n",
    "#cbar = ax.figure.colorbar(im, ax=ax)\n",
    "#cbar.ax.set_ylabel(\"Contagem\", rotation=-90, va=\"bottom\")\n",
    "\n",
    "# Rotacionar os rótulos dos eixos para melhor visualização\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "         rotation_mode=\"anchor\")\n",
    "\n",
    "# Adicionar título\n",
    "ax.set_title(\"Matriz de Confusão\")\n",
    "\n",
    "# Mostrar o gráfico\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "h3pTcFx4bqCt",
    "9i9Dog9EIik5",
    "7-25jKhUHpo6",
    "N-hAs1MuHx7U",
    "L7veztyBFjlz",
    "y628EEysd2ku",
    "va-fBkmfI3Yh"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
